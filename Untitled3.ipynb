{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN+hSZQU0GXastlvzcHv12V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# URL of the page to scrape\n","url = 'https://www.bbc.com/news'\n","\n","try:\n","    # Fetch the content from URL\n","    response = requests.get(url)\n","    response.raise_for_status()  # Raise an exception for HTTP errors\n","    html = response.content\n","except requests.exceptions.RequestException as e:\n","    print(f\"Error fetching the URL: {e}\")\n","    exit()\n","\n","# Parse HTML content\n","soup = BeautifulSoup(html, 'html.parser')\n","\n","# Find elements containing headlines\n","# You might need to change the class or tag based on the actual HTML structure of the page\n","headlines = soup.find_all('h2', class_=\"sc-4fedabc7-3 dsoipF\")\n","\n","# Create a CSV file and write the data\n","with open('headlines3.csv', 'w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","    writer.writerow(['Headline', 'URL'])\n","\n","    # Extract headlines text and URL\n","    for headline in headlines:\n","        headline_text = headline.text.strip()\n","        link = headline.find_parent('a')\n","        headline_url = link['href'] if link else '#'\n","\n","        # If the URL is relative, convert it to absolute\n","        if not headline_url.startswith('http'):\n","            headline_url = f\"https://www.bbc.com{headline_url}\"\n","\n","        writer.writerow([headline_text, headline_url])\n","\n","print(\"Data scraping complete and saved to headlines.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdQkGrN5OKQt","executionInfo":{"status":"ok","timestamp":1717755905901,"user_tz":-330,"elapsed":473,"user":{"displayName":"Gyaat","userId":"16981629338508678405"}},"outputId":"29bb7585-cf82-4660-aa7a-993fc2533c46"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Data scraping complete and saved to headlines.csv\n"]}]}]}